{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "data_dir = 'data/'\n",
    "pics = glob.glob(data_dir + '*/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "Picture = namedtuple('Picture', ['category', 'camera', 'index', 'feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_keypoints(filename):\n",
    "    image = Image.open(filename)\n",
    "    gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    names = filename.split('/')\n",
    "    return Picture(category=names[1], camera=names[2], index=names[3], feature=des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if os.path.isfile('key_ref_pics.pickle') and os.path.isfile('key_query_pics.pickle'):\n",
    "    with open('key_ref_pics.pickle', 'rb') as f, open('key_query_pics.pickle', 'rb') as g:\n",
    "        ref_pics_key = pickle.load(f)\n",
    "        query_pics_key = pickle.load(g)\n",
    "    key_feature_mat = np.load('key_feature_mat.npy')\n",
    "    \n",
    "else:\n",
    "    start = time.time()\n",
    "    chunksize = 32\n",
    "    ref_pics_key, query_pics_key = [], []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        for filename, feat_pic in zip(pics, executor.map(filename_to_keypoints, pics, chunksize=chunksize)):\n",
    "            if feat_pic.camera == 'Reference':\n",
    "                ref_pics_key.append(feat_pic)\n",
    "            else:\n",
    "                query_pics_key.append(feat_pic)\n",
    "\n",
    "    key_feature_mat = np.concatenate([pic.feature for pic in ref_pics_key])\n",
    "\n",
    "    print('Calculate Features in %.4f seconds...' % (time.time() - start))\n",
    "    \n",
    "    with open('key_ref_pics.pickle', 'wb') as f, open('key_query_pics.pickle', 'wb') as g:\n",
    "        pickle.dump(ref_pics_key, f)\n",
    "        pickle.dump(query_pics_key, g)\n",
    "\n",
    "id2info = {idx:(pic.category, pic.index) for idx, pic in enumerate(ref_pics_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "n_clusters = 4096\n",
    "kmeans = MiniBatchKMeans(init_size=n_clusters*3, n_clusters=n_clusters, random_state=0, verbose=0).fit(key_feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "def key_to_SIFT_hist_feat(picture, threshold=0.75):\n",
    "    feat = picture.feature\n",
    "    cluster_dist = kmeans.transform(feat)\n",
    "    cluster_pred = kmeans.predict(feat)\n",
    "    hist = np.zeros((n_clusters,))\n",
    "    for d, pred in zip(cluster_dist, cluster_pred):\n",
    "        first, second = sorted(d)[:2]\n",
    "        if first <= second * threshold:\n",
    "            hist[pred] += 1\n",
    "    return Picture(category=picture.category, camera=picture.camera, index=picture.index, feature=hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "start = time.time()\n",
    "chunksize = 32\n",
    "ref_pics, query_pics = [], []\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for filename, feat_pic in zip(pics, executor.map(partial(key_to_SIFT_hist_feat, threshold=1.0), ref_pics_key+query_pics_key, chunksize=chunksize)):\n",
    "        if feat_pic.camera == 'Reference':\n",
    "            ref_pics.append(feat_pic)\n",
    "        else:\n",
    "            query_pics.append(feat_pic)\n",
    "\n",
    "feature_mat = np.concatenate([[pic.feature] for pic in ref_pics])\n",
    "\n",
    "print('Calculate Features in %.4f seconds...' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "class ScoreFunctions(object):\n",
    "    def cosine_similarity(u, v):\n",
    "        return u @ v / np.linalg.norm(u) / np.linalg.norm(v)\n",
    "    def l1_dist(u, v):\n",
    "        return -np.linalg.norm((u - v), 1)\n",
    "    def l2_dist(u, v):\n",
    "        return -np.linalg.norm((u - v), 2)\n",
    "    def earth_mover_dist(u, v):\n",
    "        assert u.shape == v.shape, (u.shape, v.shape)\n",
    "        u = (u / np.linalg.norm(u, 2)).astype(np.float64)\n",
    "        v = (v / np.linalg.norm(v, 2)).astype(np.float64)\n",
    "        dist_matrix = np.fromfunction(lambda i, j: abs(i-j), (len(u), len(u)), dtype=np.float64)\n",
    "        return -emd(u, v, dist_matrix)\n",
    "    def chi_square(u, v):\n",
    "        return -cv2.compareHist(u.astype(np.float32), v.astype(np.float32), cv2.HISTCMP_CHISQR_ALT)\n",
    "    def intersect(u, v):\n",
    "        return cv2.compareHist(u.astype(np.float32), v.astype(np.float32), cv2.HISTCMP_INTERSECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(query, func, top=5):\n",
    "    score_list = [func(feat, query) for feat in feature_mat]\n",
    "    score_list = sorted(list(enumerate(score_list)), key=lambda x:x[1], reverse=True)[:top]\n",
    "    index_list = [index for index, score in score_list]\n",
    "    info_list = [id2info[index] for index in index_list]\n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_correct(query, ref):\n",
    "    return (query.category, query.index) == ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sat1and5(q, func=ScoreFunctions.cosine_similarity):\n",
    "    rankings = retrieval(q.feature.reshape(-1), func=func)\n",
    "    Sat1 = any([retrieval_correct(q, r) for r in rankings[:1]])\n",
    "    Sat5 = any([retrieval_correct(q, r) for r in rankings[:5]])\n",
    "    return Sat1, Sat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: dvd_covers\n",
      "S@1: 0.0850 S@5: 0.1700\n",
      "Category: museum_paintings\n",
      "S@1: 0.0907 S@5: 0.1374\n",
      "Category: book_covers\n",
      "S@1: 0.1980 S@5: 0.3069\n",
      "Category: business_cards\n",
      "S@1: 0.2675 S@5: 0.3175\n",
      "Category: video_frames\n",
      "S@1: 0.2150 S@5: 0.4000\n",
      "Category: cd_covers\n",
      "S@1: 0.0625 S@5: 0.1500\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "chunksize = 32\n",
    "Sat1s, Sat5s = defaultdict(list), defaultdict(list)\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for q, (Sat1, Sat5) in zip(query_pics, executor.map(partial(Sat1and5, func=ScoreFunctions.chi_square), query_pics, chunksize=chunksize)):\n",
    "        Sat1s[q.category].append(Sat1)\n",
    "        Sat5s[q.category].append(Sat5)\n",
    "\n",
    "for (c1, sat1), (c2, sat5) in zip(Sat1s.items(), Sat5s.items()):\n",
    "    assert c1 == c2\n",
    "    print('Category:', c1)\n",
    "    print('S@1: %.4f' % (sum(sat1) / len(sat1)), 'S@5: %.4f' % (sum(sat5) / len(sat5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
